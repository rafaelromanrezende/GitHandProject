# GitHand - Controle de comandos Git por gestos das mÃ£os :raised_hand_with_fingers_splayed:	
## MotivaÃ§Ã£o do projeto :thought_balloon: :
Enquanto estava escrevendo cÃ³digos, no momento em que eu precisava usar comandos especÃ­ficos da ferramenta Git, eu esquecia de alguns detalhes deles(como uma palavra ou um caractere especÃ­fico) e isso gerava erros que atrapalhavam a minha linha de raciocÃ­nio que eu estava desenvolvendo para escrever o cÃ³digo, e me atrasavam.  

Portanto, visando praticidade, pensei em uma soluÃ§Ã£o que usasse visÃ£o computacional para que, a partir de simples gestos(intuitivos e mais fÃ¡ceis de se lembrar do que linhas de cÃ³digos com vÃ¡rios caracteres especÃ­ficos), eu pudesse dinamizar os comandos Git.

## Bibliotecas e lÃ³gicas utilizadas :open_book:	:
### -OpenCv ğŸ‘€: CaptaÃ§Ã£o de frames da cÃ¢mera, bem como escrita sobre esses frames de qual gesto estÃ¡ sendo exibido

### -MediaPipe ğŸ™Œ: Uso dos frames captados pelo OpenCv para desenhar landmarks das mÃ£os juntamente com pontos, cujas coordenadas foram fundamentais para o preparo do DataSet

### -CSV ğŸ—ƒï¸: Usada para escrever o rÃ³tulo(nome do gesto da mÃ£o) como dado de saÃ­da, e as posiÃ§Ãµes dos pontos nas landmarks da mÃ£o como dados de entrada no arquivo csv(usado para o Machine Learning)

### -Pandas ğŸ¼: Usada para abrir o arquivo CSV onde estÃ£o os dados e coletÃ¡-los de modo organizado para o aprendizado de mÃ¡quina

### -SciKit-Learn ğŸ¤–: Dela, usei o algoritmo de aprendizado supervisionado de mÃ¡quina Random Forest ğŸŒ³, altamente eficiente, garantindo uma acurÃ¡cia de 94%

### -Joblib ğŸ“š: Salva/Armazena o modelo de I.A treinado para ser usado em outros arquivos de modo instantÃ¢neo

### -Tkinter :computer:	: CriaÃ§Ã£o de interface grÃ¡fica simples para o usuÃ¡rio interagir e colocar informaÃ§Ãµes , como o link do respositÃ³rio do GitHub 

### -Pillow :framed_picture: : Usada para colocar a imagem de fundo e estilizar a janela do Tkinter

### -Subprocess :keyboard: : Usada para escrever os comandos Git no terminal da IDE (no caso Visual Studio Code) correspondentes aos gestos de mÃ£o 

### -Numpy :1234:	: Usada para converter os Data Features em array para assim o modelo de mÃ¡quina conseguir fazer uma previsÃ£o de qual gesto a mÃ£o estÃ¡ fazendo, dado a posiÃ§Ã£o dos pontos nos landmarks

### -Time â²ï¸ : Usada para gerar delay de cerca de 5 segundos quando algum gesto Ã© reconhecido, a fim de evitar travamentos na execuÃ§Ã£o do cÃ³digo

## Gestos reconhecidos atÃ© entÃ£o ğŸ¤™ : 
### Primeiro :point_up: : Sinaliza o inÃ­cio de um repositÃ³rio no GitHub
### Positivo ğŸ‘: Sinaliza a permissÃ£o de submissÃ£o de um commit
### "VoltaMain" :point_left: : Sinaliza a volta para o branch main
### "V" :v:	: Sinaliza a criaÃ§Ã£o de um branch juntamente com um commit
### Ok(Trocar) ğŸ‘Œ : Sinaliza a permissÃ£o de acesso/troca para algum outro branch existente 

### Exemplo do que pode ser evitado/simplificado pelo projeto:

![Captura de tela 2025-02-27 113256](https://github.com/user-attachments/assets/e88dda29-db01-43aa-b732-b2edda581484)

Tudo isso pode ser feito apenas levantando o dedo indicador(Gesto primeiro)

### P.S âš ï¸ : Ainda hÃ¡ pequenas imprecisÃµes na determinaÃ§Ã£o de gestos, mas isso pode ser facilmente melhorado ao fornecer mais imagens ao treinamento da I.A

## Print ğŸ“¸ -  Funcionamento do GitHand :

![Captura de tela 2025-02-27 095607](https://github.com/user-attachments/assets/f4621186-51d2-4771-9755-b89d7f8c2c29)
